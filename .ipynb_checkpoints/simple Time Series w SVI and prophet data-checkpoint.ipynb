{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make up time series\n",
    "\n",
    "$$y = 0 + 0.01t + 0.4sin(1\\times\\frac{2\\pi t}{7}) + 0.2cos(1\\times\\frac{2\\pi t}{7}) + 0.1sin(2\\times\\frac{2\\pi t}{7}) + 0.3cos(2\\times\\frac{2\\pi t}{7}) + 0.5sin(3\\times\\frac{2\\pi t}{7}) + 0.7cos(3\\times\\frac{2\\pi t}{7})$$\n",
    "\n",
    "$$\\text{coefficients} = [0, 0.01, 0.4, 0.2, 0.1, 0.3, 0.5, 0.2]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.date_range(start='2010-01-01', end='2020-01-01').values\n",
    "t = ds.astype(int)/(60*60*24*1e9)\n",
    "t_weekly = 2*math.pi*t/7\n",
    "\n",
    "y = 0.01*t \n",
    "y += 0.4*np.sin(1*t_weekly)+0.2*np.cos(1*t_weekly)\n",
    "y += 0.10*np.sin(2*t_weekly)+0.3*np.cos(2*t_weekly)\n",
    "y += 0.5*np.sin(3*t_weekly)+0.2*np.cos(3*t_weekly)\n",
    "y += np.random.randn(t.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"ds\": ds, \"y\":y})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(ds[-365:], y[-365:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lots of code taken from \n",
    "# https://towardsdatascience.com/linear-regression-with-pytorch-eb6dedead817\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "\n",
    "class Chronos(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 criterion=None,\n",
    "                 optimizer=\"adam\",\n",
    "                 weekly_seasonality=0,\n",
    "                 epochs=200):\n",
    "        super(Chronos, self).__init__()\n",
    "        pyro.set_rng_seed(1)\n",
    "        \n",
    "        self.optimizer_name = optimizer\n",
    "        \n",
    "        self.criterion = criterion\n",
    "        if (self.criterion is None):\n",
    "            self.criterion = nn.MSELoss()\n",
    "            \n",
    "        self.weekly_seasonality = weekly_seasonality\n",
    "        self.epochs = epochs\n",
    "    \n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = self.linear(X)\n",
    "        return out.view(-1, 1)\n",
    "    \n",
    "    def backward(self, X, y):\n",
    "        inputs = torch.from_numpy(X)\n",
    "        labels = torch.from_numpy(y).view(-1,1)\n",
    "        self.optim.zero_grad()\n",
    "        \n",
    "        outputs = self(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def _prepare_data_from_date(self, X):\n",
    "        #X.loc[: ,'ts'] = 0\n",
    "        X.loc[: ,'ts'] = X['ds'].astype(np.int64)/(60*60*24*1e9)\n",
    "\n",
    "        for o in range(1, self.weekly_seasonality+1):\n",
    "            #X.loc[:, f'w_sin_{o}'] = 0.0\n",
    "            #X.loc[:, f'w_cos_{o}'] = 0.0\n",
    "            X.loc[:, f'w_sin_{o}'] = np.sin(2*math.pi*o*X['ts']/7)\n",
    "            X.loc[:, f'w_cos_{o}'] = np.cos(2*math.pi*o*X['ts']/7)\n",
    "\n",
    "        X = X.drop('ds', axis=1)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def fit(self, Y):\n",
    "        \n",
    "        X = Y[['ds']].copy()\n",
    "        X = self._prepare_data_from_date(X)\n",
    "        y = Y['y'].copy()\n",
    "        \n",
    "        #X = np.c_[np.ones(X.shape[0]), X].astype(np.float32)\n",
    "        \n",
    "        # if X and y are pandas df\n",
    "        X = X.values.astype(np.float32)\n",
    "        y = y.values.astype(np.float32)\n",
    "        \n",
    "        \n",
    "        self.feature_number = X.shape[1]\n",
    "        self.target_number = 1 if len(y.shape) == 1 else y.shape[1]\n",
    "        \n",
    "        \n",
    "        self.linear = nn.Linear(self.feature_number, self.target_number)\n",
    "        \n",
    "        if (self.optimizer_name == \"adam\"):\n",
    "            self.optim = optim.Adam(self.parameters(), lr=0.1)\n",
    "        else:\n",
    "            raise ValueError(f'Optimizer {self.optimizer_name} is not recognized')\n",
    "        \n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            self.backward(X, y)\n",
    "            \n",
    "            \n",
    "    def predict(self, X):\n",
    "        \n",
    "        \n",
    "        X = X[['ds']].copy()\n",
    "        X = self._prepare_data_from_date(X)\n",
    "        X = X.values.astype(np.float32)\n",
    "        X = torch.from_numpy(X)\n",
    "        \n",
    "        output = self(X)\n",
    "        \n",
    "        return output.detach().numpy()\n",
    "        \n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def coef_(self):\n",
    "        \n",
    "        return self.linear.weight.detach().numpy()\n",
    "    \n",
    "    @property\n",
    "    def const_(self):\n",
    "        return self.linear.bias.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = Chronos(weekly_seasonality=3, \n",
    "                   epochs=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.const_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = my_model.predict(data)\n",
    "y = data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "max_points=100\n",
    "plt.plot(data.iloc[-max_points:]['ds'], y_pred[-max_points:], label=\"prediction\")\n",
    "plt.plot(data.iloc[-max_points:]['ds'], y[-max_points:], label=\"true_censored\")\n",
    "\n",
    "plt.title(f'Sales')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USING Pyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lots of code taken from \n",
    "# https://towardsdatascience.com/linear-regression-with-pytorch-eb6dedead817\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pyro.optim as optim\n",
    "import math\n",
    "import time\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.nn import PyroSample\n",
    "from pyro.nn import PyroModule\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal, AutoMultivariateNormal, AutoDelta, init_to_mean\n",
    "\n",
    "from pyro.infer import SVI, Trace_ELBO, Predictive\n",
    "\n",
    "\n",
    "class Chronos(PyroModule):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 weekly_seasonality=0,\n",
    "                 yearly_seasonality=0,\n",
    "                 epochs=200,\n",
    "                 lr=0.1,\n",
    "                 random_state=None):\n",
    "        pyro.clear_param_store()\n",
    "        super(Chronos, self).__init__()\n",
    "        \n",
    "        if (random_state is None):\n",
    "            pyro.set_rng_seed(int(time.time()))\n",
    "        else:\n",
    "            pyro.set_rng_seed(random_state)\n",
    "        \n",
    "        self.weekly_seasonality = weekly_seasonality\n",
    "        self.yearly_seasonality = yearly_seasonality\n",
    "        self.learning_rate=lr\n",
    "        self.epochs = epochs\n",
    "    \n",
    "    #######################################################\n",
    "    def forward(self, X, y=None):\n",
    "        \n",
    "        sigma = 0.02\n",
    "        sigma = pyro.sample(\"sigma\", dist.Uniform(0., 1.))\n",
    "        \n",
    "        mean = self.linear(X).view(-1)\n",
    "        \n",
    "        with pyro.plate(\"data\", X.shape[0]):\n",
    "            obs = pyro.sample(\"obs\", dist.Normal(mean, sigma), obs=y)\n",
    "        return mean\n",
    "    \n",
    "    #######################################################\n",
    "    def _prepare_data_from_date(self, X):\n",
    "        X.loc[: ,'ts'] = pd.to_datetime(X['ds']).astype(np.int64)/(60*60*24*1e9)\n",
    "        \n",
    "\n",
    "        for o in range(1, self.weekly_seasonality+1):\n",
    "            X.loc[:, f'w_sin_{o}'] = np.sin(2*math.pi*o*X['ts']/7)\n",
    "            X.loc[:, f'w_cos_{o}'] = np.cos(2*math.pi*o*X['ts']/7)\n",
    "            \n",
    "        for o in range(1, self.yearly_seasonality+1):\n",
    "            X.loc[:, f'y_sin_{o}'] = np.sin(2*math.pi*o*X['ts']/365.25)\n",
    "            X.loc[:, f'y_cos_{o}'] = np.cos(2*math.pi*o*X['ts']/365.25)\n",
    "\n",
    "        X = X.drop('ds', axis=1)\n",
    "        \n",
    "        return X.values.astype(np.float32)\n",
    "    \n",
    "    #######################################################\n",
    "    def fit(self, Y):\n",
    "        \n",
    "        X = Y[['ds']].copy()\n",
    "        X = self._prepare_data_from_date(X)\n",
    "\n",
    "        y = Y['y'].values.astype(np.float32)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.feature_number = X.shape[1]\n",
    "        self.target_number = 1 if len(y.shape) == 1 else y.shape[1]\n",
    "        \n",
    "        \n",
    "        # change the linear layers to be a learnable distribution collection\n",
    "        self.linear = PyroModule[nn.Linear](self.feature_number, \n",
    "                                            self.target_number)\n",
    "        \n",
    "        self.linear.weight = PyroSample(dist.Normal(0., 1.).expand([self.target_number,\n",
    "                                                                    self.feature_number]).to_event(2))\n",
    "        self.linear.bias = PyroSample(dist.Normal(0, 10.0).expand([self.target_number]).to_event(1))\n",
    "        \n",
    "        \n",
    "        X = torch.from_numpy(X)\n",
    "        y = torch.from_numpy(y)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.guide = AutoDiagonalNormal(self)\n",
    "        #self.guide = AutoDelta(self)\n",
    "        self.guide = AutoMultivariateNormal(self)\n",
    "        \n",
    "        self.optimizer = pyro.optim.ClippedAdam({\"lr\": self.learning_rate})\n",
    "        self.inference = SVI(self, self.guide, self.optimizer, loss=Trace_ELBO())\n",
    "        \n",
    "        epoch_printout = self.epochs//10\n",
    "        \n",
    "        epoch_list = []\n",
    "        losses_list = []\n",
    "        \n",
    "        pyro.clear_param_store()\n",
    "        for epoch in range(self.epochs):\n",
    "            # calculate the loss and take a gradient step\n",
    "            loss = self.inference.step(X, y)\n",
    "            normalized_loss = loss/X.shape[0]\n",
    "            \n",
    "            break_time = False\n",
    "            if (epoch % epoch_printout == 0):\n",
    "                print(\"[iteration %04d] loss: %.4f\" % (epoch + 1, loss))\n",
    "                \n",
    "                y_pred = self.predict(Y)[\"y_hat\"]\n",
    "                \n",
    "                \n",
    "                MAE = np.mean(np.abs(y_pred - y.detach().numpy()))\n",
    "                print(MAE)\n",
    "                if (MAE < 1.0):\n",
    "                    break_time = True\n",
    "            \n",
    "                \n",
    "            epoch_list.append(epoch)\n",
    "            losses_list.append(loss)\n",
    "            if (break_time):\n",
    "                break\n",
    "            \n",
    "            \n",
    "        return pd.DataFrame({\"epoch\": epoch_list,\n",
    "                             \"loss\": losses_list})\n",
    "    #######################################################\n",
    "    def predict(self, X, interval=0.9):\n",
    "        \n",
    "        \n",
    "        \n",
    "        X = X[['ds']].copy()\n",
    "        X = self._prepare_data_from_date(X)\n",
    "\n",
    "        X = torch.from_numpy(X)\n",
    "        \n",
    "        predictive = Predictive(self, \n",
    "                                guide=self.guide,\n",
    "                                num_samples=1800,\n",
    "                                return_sites=(\"_RETURN\",))\n",
    "        \n",
    "        samples = predictive(X)\n",
    "        \n",
    "        interval_value = (1.0 - interval)/2\n",
    "        \n",
    "        \n",
    "        stats = {}\n",
    "        for key, values in samples.items():\n",
    "            interval_number_bottom = int(values.shape[0]*interval_value)\n",
    "            interval_number_top = int(values.shape[0]*(1.0-interval_value))\n",
    "            \n",
    "            \n",
    "            stats = {\"y_hat\": torch.mean(values, axis=0).detach().numpy(),\n",
    "                     \"y_hat_std\": torch.std(values, axis=0).detach().numpy(),\n",
    "                     \"y_lower\": values.kthvalue(interval_number_bottom, axis=0)[0].detach().numpy(),\n",
    "                     \"y_upper\": values.kthvalue(interval_number_top, axis=0)[0].detach().numpy()}\n",
    "        #output = self(X)\n",
    "        \n",
    "            stats = pd.DataFrame(stats)\n",
    "        return stats\n",
    "        \n",
    "        \n",
    "    #######################################################\n",
    "    @property\n",
    "    def coef_(self):\n",
    "        all_params = pyro.param('guide.loc').detach().numpy()\n",
    "        \n",
    "        # The first elements is the sigma we looked at\n",
    "        coefficients_and_bias = all_params[-self.feature_number-1:]\n",
    "        \n",
    "        coefficients = coefficients_and_bias[:self.feature_number] # If there is a bias\n",
    "                                                        # it's in the last spot\n",
    "        return coefficients\n",
    "    \n",
    "    #######################################################\n",
    "    @property\n",
    "    def const_(self):\n",
    "        all_params = pyro.param('guide.loc').detach().numpy()\n",
    "        \n",
    "        # The first elements is the sigma we looked at\n",
    "        coefficients_and_bias = all_params[-self.feature_number-1:]\n",
    "        \n",
    "        bias = coefficients_and_bias[self.feature_number:]\n",
    "        return bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pyro_model = Chronos(weekly_seasonality=3,\n",
    "                        epochs=20000,\n",
    "                        lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = my_pyro_model.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = my_pyro_model.predict(data, interval=0.9)\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred[\"y_hat\"]\n",
    "y_lower = pred[\"y_lower\"]\n",
    "y_upper = pred[\"y_upper\"]\n",
    "\n",
    "y = data['y']\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "max_points = 365\n",
    "plt.plot(data['ds'].iloc[-max_points:], \n",
    "         y_pred[-max_points:],\n",
    "         label=\"prediction\",\n",
    "         c=\"blue\")\n",
    "plt.fill_between(data['ds'].iloc[-max_points:],\n",
    "                 y_lower[-max_points:],\n",
    "                 y_upper[-max_points:],\n",
    "                 alpha=0.1,\n",
    "                 color=\"blue\")\n",
    "plt.scatter(data['ds'].iloc[-max_points:], \n",
    "         y[-max_points:], \n",
    "         label=\"true_censored\",\n",
    "         c=\"red\")\n",
    "\n",
    "plt.title(f'Sales')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pyro_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pyro_model.const_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-12-10</td>\n",
       "      <td>9.590761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-12-11</td>\n",
       "      <td>8.519590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-12-12</td>\n",
       "      <td>8.183677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-12-13</td>\n",
       "      <td>8.072467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-12-14</td>\n",
       "      <td>7.893572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ds         y\n",
       "0  2007-12-10  9.590761\n",
       "1  2007-12-11  8.519590\n",
       "2  2007-12-12  8.183677\n",
       "3  2007-12-13  8.072467\n",
       "4  2007-12-14  7.893572"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prophet_df = pd.read_csv('data/prophetData.csv')\n",
    "prophet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ch2 = Chronos(weekly_seasonality=3,\n",
    "                 yearly_seasonality=10,\n",
    "                 epochs=60000,\n",
    "                 lr=0.001,\n",
    "                 random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 18184720437.7988\n",
      "1226.761\n",
      "[iteration 6001] loss: 28484.3496\n",
      "14.805563\n",
      "[iteration 12001] loss: 130103.0520\n",
      "12.444178\n",
      "[iteration 18001] loss: 424237.4237\n",
      "9.1012125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-2c7503cf7e80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_ch2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprophet_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-131-ced3058cea4d>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, Y)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;31m# calculate the loss and take a gradient step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0mnormalized_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pyroenv/lib/python3.8/site-packages/pyro/infer/svi.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# get loss and compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mparam_capture\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_and_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         params = set(site[\"value\"].unconstrained()\n",
      "\u001b[0;32m/anaconda3/envs/pyroenv/lib/python3.8/site-packages/pyro/infer/trace_elbo.py\u001b[0m in \u001b[0;36mloss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# grab a trace from the generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_traces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0mloss_particle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurrogate_loss_particle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_differentiable_loss_particle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_particle\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pyroenv/lib/python3.8/site-packages/pyro/infer/elbo.py\u001b[0m in \u001b[0;36m_get_traces\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/pyroenv/lib/python3.8/site-packages/pyro/infer/trace_elbo.py\u001b[0m in \u001b[0;36m_get_trace\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0magainst\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \"\"\"\n\u001b[0;32m---> 52\u001b[0;31m         model_trace, guide_trace = get_importance_trace(\n\u001b[0m\u001b[1;32m     53\u001b[0m             \"flat\", self.max_plate_nesting, model, guide, args, kwargs)\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_validation_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pyroenv/lib/python3.8/site-packages/pyro/infer/enum.py\u001b[0m in \u001b[0;36mget_importance_trace\u001b[0;34m(graph_type, max_plate_nesting, model, guide, args, kwargs, detach)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mmodel_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mguide_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_score_parts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_validation_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msite\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pyroenv/lib/python3.8/site-packages/pyro/poutine/trace_struct.py\u001b[0m in \u001b[0;36mcompute_score_parts\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m                 \u001b[0;31m# to correctly scale each of its three parts.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m                     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fn\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_parts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"args\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pyroenv/lib/python3.8/site-packages/pyro/distributions/distribution.py\u001b[0m in \u001b[0;36mscore_parts\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mScoreParts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \"\"\"\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_rsample\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mScoreParts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_term\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pyroenv/lib/python3.8/site-packages/torch/distributions/multivariate_normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_batch_mahalanobis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unbroadcasted_scale_tril\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0mhalf_log_det\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unbroadcasted_scale_tril\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiagonal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mhalf_log_det\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pyroenv/lib/python3.8/site-packages/torch/distributions/multivariate_normal.py\u001b[0m in \u001b[0;36m_batch_mahalanobis\u001b[0;34m(bL, bx)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mbx_new_shape\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msx\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0msL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mbx_new_shape\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mbx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbx_new_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;31m# Permute bx to make it have shape (..., 1, j, i, 1, n)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     permute_dims = (list(range(outer_batch_dims)) +\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "my_ch2.fit(prophet_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = my_ch2.predict(prophet_df, interval=0.95)\n",
    "#pred += 4\n",
    "pred.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "\n",
    "max_points = 3650\n",
    "x = pd.to_datetime(prophet_df.iloc[-max_points:]['ds'])\n",
    "plt.scatter(x, \n",
    "            prophet_df.iloc[-max_points:]['y'], \n",
    "            c=\"blue\", \n",
    "            label=\"true\")\n",
    "plt.plot(x, \n",
    "         pred.iloc[-max_points:]['y_hat'], \n",
    "         c=\"red\", \n",
    "         label=\"prediction\")\n",
    "plt.fill_between(x,\n",
    "                 pred.iloc[-max_points:]['y_lower'],\n",
    "                 pred.iloc[-max_points:]['y_upper'],\n",
    "                 color=\"red\",\n",
    "                 alpha=0.1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(pred['y_hat'] - prophet_df['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
